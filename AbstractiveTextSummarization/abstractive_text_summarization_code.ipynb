{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of 21_1_2020_ABSTRACTIVE.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FudqErdQSZTL",
        "colab_type": "text"
      },
      "source": [
        "**IMPORTING MODULES**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rXQ9bNySVKH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkWjQTnLSejB",
        "colab_type": "text"
      },
      "source": [
        "**LOADING DATASET**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhgFu8oKOxMu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data=pd.read_csv(\"Reviews half.csv\",nrows=18280)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHPCq7IaSl41",
        "colab_type": "text"
      },
      "source": [
        "**DATA EXPLORATION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGSNW_ylPZ-s",
        "colab_type": "code",
        "outputId": "b0436984-6fe2-47a4-dccf-b19cc1ff375b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Good Quality Dog Food</td>\n",
              "      <td>I have bought several of the Vitality canned d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Not as Advertised</td>\n",
              "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"Delight\" says it all</td>\n",
              "      <td>This is a confection that has been around a fe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Cough Medicine</td>\n",
              "      <td>If you are looking for the secret ingredient i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Great taffy</td>\n",
              "      <td>Great taffy at a great price.  There was a wid...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Summary                                               Text\n",
              "0  Good Quality Dog Food  I have bought several of the Vitality canned d...\n",
              "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...\n",
              "2  \"Delight\" says it all  This is a confection that has been around a fe...\n",
              "3         Cough Medicine  If you are looking for the secret ingredient i...\n",
              "4            Great taffy  Great taffy at a great price.  There was a wid..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kH9xiJVKPb3s",
        "colab_type": "code",
        "outputId": "09c115dc-61a2-479d-9271-8a45fa9e41de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "data.tail()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>18275</th>\n",
              "      <td>Always Great Tea</td>\n",
              "      <td>This tea is a very great substitute for coffee...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18276</th>\n",
              "      <td>Weak; little flavor</td>\n",
              "      <td>I decided to try this tea based on the descrip...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18277</th>\n",
              "      <td>Disappointed</td>\n",
              "      <td>I had high hopes for this tea, but I have to a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18278</th>\n",
              "      <td>Disappointment</td>\n",
              "      <td>I was sadly disappointed in this brand of Assa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18279</th>\n",
              "      <td>Great tea</td>\n",
              "      <td>It is hard to get Assam tea in the store, let ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   Summary                                               Text\n",
              "18275     Always Great Tea  This tea is a very great substitute for coffee...\n",
              "18276  Weak; little flavor  I decided to try this tea based on the descrip...\n",
              "18277         Disappointed  I had high hopes for this tea, but I have to a...\n",
              "18278       Disappointment  I was sadly disappointed in this brand of Assa...\n",
              "18279            Great tea  It is hard to get Assam tea in the store, let ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94hNO3fUPmv7",
        "colab_type": "code",
        "outputId": "7ce17529-f6fa-47b7-960b-a94f8002a430",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18280, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCS2zs69PeHD",
        "colab_type": "code",
        "outputId": "ae24946c-b6b3-455f-f35f-5d88683a2809",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "data.dtypes"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Summary    object\n",
              "Text       object\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxVCbZupPgsJ",
        "colab_type": "code",
        "outputId": "f6c53630-f481-45f5-ad5e-8d0d1cb56158",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        }
      },
      "source": [
        "data.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>18280</td>\n",
              "      <td>18280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>15468</td>\n",
              "      <td>17670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>Delicious</td>\n",
              "      <td>Diamond Almonds&lt;br /&gt;Almonds are a good source...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>72</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Summary                                               Text\n",
              "count       18280                                              18280\n",
              "unique      15468                                              17670\n",
              "top     Delicious  Diamond Almonds<br />Almonds are a good source...\n",
              "freq           72                                                  7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrErSThWPirU",
        "colab_type": "code",
        "outputId": "b0cc43ba-bf5c-486c-d9ba-14abd42ff29b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Summary', 'Text'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaMdhwyxSrir",
        "colab_type": "text"
      },
      "source": [
        "**CHECKING FOR MISSING VALUES**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EiOHXW4Pkq6",
        "colab_type": "code",
        "outputId": "f9eebb2f-6bd3-476d-e340-a8ca8d1e1de8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "data.isnull().sum()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Summary    0\n",
              "Text       0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xutSu3EQSvFX",
        "colab_type": "text"
      },
      "source": [
        "**DATA PREPROCESSING**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlF4LsLHPxqR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "contraction_mapping = { \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
        "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
        "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
        "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
        "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
        "                           \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
        "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
        "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
        "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
        "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
        "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
        "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
        "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
        "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
        "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
        "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
        "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
        "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
        "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
        "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
        "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
        "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
        "                           \"you're\": \"you are\", \"you've\": \"you have\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRtdzInFQHTB",
        "colab_type": "code",
        "outputId": "cc172f80-132f-4321-8300-e615754b3c6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPJFlTi4QLfl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stop_words = set(stopwords.words('english')) \n",
        "\n",
        "def text_cleaner(text,num):\n",
        "    newString = text.lower()\n",
        "    newString = ' '.join([contraction_mapping[t] \n",
        "                          if t in contraction_mapping else t for t in newString.split(\" \")])    \n",
        "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString) \n",
        "    if(num==0):\n",
        "        tokens = [w for w in newString.split() if not w in stop_words]\n",
        "    else:\n",
        "        tokens=newString.split()\n",
        "    long_words=[]\n",
        "    for i in tokens:\n",
        "        if len(i)>1:                                                 #removing short word\n",
        "            long_words.append(i)   \n",
        "    return (\" \".join(long_words)).strip()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdIWWssKRnnn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cleaned_text = []\n",
        "for t in data['Text']:\n",
        "    cleaned_text.append(text_cleaner(t,0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjbrhW0KR43G",
        "colab_type": "code",
        "outputId": "f86962b8-b5d0-4535-f792-797e2c631e40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "cleaned_text[:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better',\n",
              " 'product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo',\n",
              " 'confection around centuries light pillowy citrus gelatin nuts case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat familiar story lewis lion witch wardrobe treat seduces edmund selling brother sisters witch',\n",
              " 'looking secret ingredient robitussin believe found got addition root beer extract ordered good made cherry soda flavor medicinal',\n",
              " 'great taffy great price wide assortment yummy taffy delivery quick taffy lover deal']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifPmb2vDR96O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cleaned_summary = []\n",
        "for t in data['Summary']:\n",
        "    cleaned_summary.append(text_cleaner(t,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPfOCtuJSBir",
        "colab_type": "code",
        "outputId": "082480cd-e2c4-4fe2-b2ad-16e74410b11a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "cleaned_summary[:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['good quality dog food',\n",
              " 'not as advertised',\n",
              " 'delight says it all',\n",
              " 'cough medicine',\n",
              " 'great taffy']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KKHioCsSFAg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['cleaned_text']=cleaned_text\n",
        "data['cleaned_summary']=cleaned_summary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isXnO8jYSHTv",
        "colab_type": "code",
        "outputId": "9b44de1d-31bf-4e87-cff1-290e8db88c78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "      <th>cleaned_text</th>\n",
              "      <th>cleaned_summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Good Quality Dog Food</td>\n",
              "      <td>I have bought several of the Vitality canned d...</td>\n",
              "      <td>bought several vitality canned dog food produc...</td>\n",
              "      <td>good quality dog food</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Not as Advertised</td>\n",
              "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
              "      <td>product arrived labeled jumbo salted peanuts p...</td>\n",
              "      <td>not as advertised</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"Delight\" says it all</td>\n",
              "      <td>This is a confection that has been around a fe...</td>\n",
              "      <td>confection around centuries light pillowy citr...</td>\n",
              "      <td>delight says it all</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Cough Medicine</td>\n",
              "      <td>If you are looking for the secret ingredient i...</td>\n",
              "      <td>looking secret ingredient robitussin believe f...</td>\n",
              "      <td>cough medicine</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Great taffy</td>\n",
              "      <td>Great taffy at a great price.  There was a wid...</td>\n",
              "      <td>great taffy great price wide assortment yummy ...</td>\n",
              "      <td>great taffy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Summary  ...        cleaned_summary\n",
              "0  Good Quality Dog Food  ...  good quality dog food\n",
              "1      Not as Advertised  ...      not as advertised\n",
              "2  \"Delight\" says it all  ...    delight says it all\n",
              "3         Cough Medicine  ...         cough medicine\n",
              "4            Great taffy  ...            great taffy\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACqrmCdeSKmZ",
        "colab_type": "code",
        "outputId": "e1e8bae6-ece8-4fec-d4c0-9ee00e47ddb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18280, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DH2wJPNDXT5P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['Summary'] = data['Summary'].apply(lambda x : 'sostok '+ x + ' eostok')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVjn_e-DgO6b",
        "colab_type": "text"
      },
      "source": [
        "**SPLITTING THE DATASET**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnSwf-onSPw7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_tr,x_val,y_tr,y_val=train_test_split(np.array(data['Text']),np.array(data['Summary']),\n",
        "                                       test_size=0.2,random_state=0,shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wQgZLmad5DU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_text_len=30"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxiQ5rt4gkMk",
        "colab_type": "text"
      },
      "source": [
        "**IMPORTING THE MODULES REQUIRED FOR MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aa_KNEJHd2Ba",
        "colab_type": "code",
        "outputId": "a24fe2f8-4a21-4d36-e024-32a383fc0e1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        }
      },
      "source": [
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHrtAxkCgx-i",
        "colab_type": "text"
      },
      "source": [
        "**PREPARING THE TOKENIZER**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9u0gbfD4eOcU",
        "colab_type": "code",
        "outputId": "69b3e5a8-9dda-4bd9-822e-674c3707bf67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "#prepare a tokenizer for reviews on training data\n",
        "x_tokenizer = Tokenizer() \n",
        "x_tokenizer.fit_on_texts(list(x_tr))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPy0YSjKeOZE",
        "colab_type": "code",
        "outputId": "6416b2fe-6b98-4bf3-fa4c-7fe54bb058ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "thresh=4\n",
        "\n",
        "cnt=0\n",
        "tot_cnt=0\n",
        "freq=0\n",
        "tot_freq=0\n",
        "\n",
        "for key,value in x_tokenizer.word_counts.items():\n",
        "    tot_cnt=tot_cnt+1\n",
        "    tot_freq=tot_freq+value\n",
        "    if(value<thresh):\n",
        "        cnt=cnt+1\n",
        "        freq=freq+value\n",
        "    \n",
        "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
        "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "% of rare words in vocabulary: 63.79210460978234\n",
            "Total Coverage of rare words: 1.9002640736105187\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYA6KSYGeOVr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
        "x_tokenizer.fit_on_texts(list(x_tr))\n",
        "\n",
        "#convert text sequences into integer sequences\n",
        "x_tr_seq    =   x_tokenizer.texts_to_sequences(x_tr) \n",
        "x_val_seq   =   x_tokenizer.texts_to_sequences(x_val)\n",
        "\n",
        "#padding zero upto maximum length\n",
        "x_tr    =   pad_sequences(x_tr_seq,  maxlen=max_text_len, padding='post')\n",
        "x_val   =   pad_sequences(x_val_seq, maxlen=max_text_len, padding='post')\n",
        "\n",
        "#size of vocabulary ( +1 for padding token)\n",
        "x_voc   =  x_tokenizer.num_words + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMQgDp35eOTk",
        "colab_type": "code",
        "outputId": "5d69553f-6b39-405c-fe14-c7deba949152",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_voc"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8751"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IGwOC6heWvy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#prepare a tokenizer for reviews on training data\n",
        "y_tokenizer = Tokenizer()   \n",
        "y_tokenizer.fit_on_texts(list(y_tr))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fz9W2FOFg5iQ",
        "colab_type": "text"
      },
      "source": [
        "**RAREWORDS AND ITS COVERAGE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97lwf9TKeOPj",
        "colab_type": "code",
        "outputId": "695cc49a-38a2-44a1-d88d-faca2819143d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "thresh=6\n",
        "\n",
        "cnt=0\n",
        "tot_cnt=0\n",
        "freq=0\n",
        "tot_freq=0\n",
        "\n",
        "for key,value in y_tokenizer.word_counts.items():\n",
        "    tot_cnt=tot_cnt+1\n",
        "    tot_freq=tot_freq+value\n",
        "    if(value<thresh):\n",
        "        cnt=cnt+1\n",
        "        freq=freq+value\n",
        "    \n",
        "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
        "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "% of rare words in vocabulary: 79.89194664865778\n",
            "Total Coverage of rare words: 8.980498144015431\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfExH0UienkS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_summary_len=8"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ic-gYv0XeONL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
        "y_tokenizer.fit_on_texts(list(y_tr))\n",
        "\n",
        "#convert text sequences into integer sequences\n",
        "y_tr_seq    =   y_tokenizer.texts_to_sequences(y_tr) \n",
        "y_val_seq   =   y_tokenizer.texts_to_sequences(y_val) \n",
        "\n",
        "#padding zero upto maximum length\n",
        "y_tr    =   pad_sequences(y_tr_seq, maxlen=max_summary_len, padding='post')\n",
        "y_val   =   pad_sequences(y_val_seq, maxlen=max_summary_len, padding='post')\n",
        "\n",
        "#size of vocabulary\n",
        "y_voc  =   y_tokenizer.num_words +1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EypjXQFej3z",
        "colab_type": "code",
        "outputId": "8abcc2c7-b469-49e4-f2af-8fcb79ce438c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_voc"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1192"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLgQDIf8euGb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from attention import AttentionLayer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USchsk_ZhANz",
        "colab_type": "text"
      },
      "source": [
        "**BUILDING THE MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OP1V1LNKdcBT",
        "colab_type": "code",
        "outputId": "58eb7556-a2c1-49d7-c6c8-3fd795529d34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 810
        }
      },
      "source": [
        "from keras import backend as K \n",
        "K.clear_session()\n",
        "\n",
        "latent_dim = 300\n",
        "embedding_dim=100\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(max_text_len,))\n",
        "\n",
        "#embedding layer\n",
        "enc_emb =  Embedding(x_voc, embedding_dim,trainable=True)(encoder_inputs)\n",
        "\n",
        "#encoder lstm 1\n",
        "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
        "\n",
        "#encoder lstm 2\n",
        "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
        "\n",
        "#encoder lstm 3\n",
        "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n",
        "\n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "\n",
        "#embedding layer\n",
        "dec_emb_layer = Embedding(y_voc, embedding_dim,trainable=True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True,dropout=0.4,recurrent_dropout=0.2)\n",
        "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n",
        "\n",
        "# Attention layer\n",
        "attn_layer = AttentionLayer(name='attention_layer')\n",
        "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
        "\n",
        "# Concat attention input and decoder LSTM output\n",
        "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
        "\n",
        "#dense layer\n",
        "decoder_dense =  TimeDistributed(Dense(y_voc, activation='softmax'))\n",
        "decoder_outputs = decoder_dense(decoder_concat_input)\n",
        "\n",
        "# Define the model \n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:107: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:111: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 30)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 30, 100)      875100      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 30, 300), (N 481200      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 30, 300), (N 721200      lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 100)    119200      input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, 30, 300), (N 721200      lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   [(None, None, 300),  481200      embedding_1[0][0]                \n",
            "                                                                 lstm_2[0][1]                     \n",
            "                                                                 lstm_2[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "attention_layer (AttentionLayer ((None, None, 300),  180300      lstm_2[0][0]                     \n",
            "                                                                 lstm_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concat_layer (Concatenate)      (None, None, 600)    0           lstm_3[0][0]                     \n",
            "                                                                 attention_layer[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed (TimeDistribut (None, None, 1192)   716392      concat_layer[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 4,295,792\n",
            "Trainable params: 4,295,792\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMnn6f-wdqVD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uInHfyafZdm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uacXovbYfcBT",
        "colab_type": "code",
        "outputId": "ea174e3b-d4aa-4978-b65e-217aa9f1a6ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 793
        }
      },
      "source": [
        "history=model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:] ,epochs=100,callbacks=[es],batch_size=256, validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 14624 samples, validate on 3656 samples\n",
            "Epoch 1/100\n",
            "14624/14624 [==============================] - 251s 17ms/sample - loss: 3.5766 - val_loss: 3.0838\n",
            "Epoch 2/100\n",
            "14624/14624 [==============================] - 243s 17ms/sample - loss: 2.9992 - val_loss: 2.9178\n",
            "Epoch 3/100\n",
            "14624/14624 [==============================] - 244s 17ms/sample - loss: 2.8908 - val_loss: 2.8497\n",
            "Epoch 4/100\n",
            "14624/14624 [==============================] - 245s 17ms/sample - loss: 2.8308 - val_loss: 2.8062\n",
            "Epoch 5/100\n",
            "14624/14624 [==============================] - 243s 17ms/sample - loss: 2.7734 - val_loss: 2.7687\n",
            "Epoch 6/100\n",
            "14624/14624 [==============================] - 243s 17ms/sample - loss: 2.7160 - val_loss: 2.7520\n",
            "Epoch 7/100\n",
            "14624/14624 [==============================] - 243s 17ms/sample - loss: 2.6640 - val_loss: 2.7223\n",
            "Epoch 8/100\n",
            "14624/14624 [==============================] - 244s 17ms/sample - loss: 2.6133 - val_loss: 2.6857\n",
            "Epoch 9/100\n",
            "14624/14624 [==============================] - 245s 17ms/sample - loss: 2.5602 - val_loss: 2.6515\n",
            "Epoch 10/100\n",
            "14624/14624 [==============================] - 244s 17ms/sample - loss: 2.5148 - val_loss: 2.5932\n",
            "Epoch 11/100\n",
            "14624/14624 [==============================] - 243s 17ms/sample - loss: 2.4613 - val_loss: 2.5829\n",
            "Epoch 12/100\n",
            "14624/14624 [==============================] - 244s 17ms/sample - loss: 2.4163 - val_loss: 2.5481\n",
            "Epoch 13/100\n",
            "14624/14624 [==============================] - 243s 17ms/sample - loss: 2.3736 - val_loss: 2.5293\n",
            "Epoch 14/100\n",
            "14624/14624 [==============================] - 243s 17ms/sample - loss: 2.3322 - val_loss: 2.5149\n",
            "Epoch 15/100\n",
            "14624/14624 [==============================] - 243s 17ms/sample - loss: 2.2926 - val_loss: 2.5245\n",
            "Epoch 16/100\n",
            "14624/14624 [==============================] - 245s 17ms/sample - loss: 2.2551 - val_loss: 2.4936\n",
            "Epoch 17/100\n",
            "14624/14624 [==============================] - 243s 17ms/sample - loss: 2.2193 - val_loss: 2.4706\n",
            "Epoch 18/100\n",
            "14624/14624 [==============================] - 244s 17ms/sample - loss: 2.1842 - val_loss: 2.4463\n",
            "Epoch 19/100\n",
            "14624/14624 [==============================] - 244s 17ms/sample - loss: 2.1498 - val_loss: 2.4877\n",
            "Epoch 20/100\n",
            "14624/14624 [==============================] - 243s 17ms/sample - loss: 2.1179 - val_loss: 2.4514\n",
            "Epoch 00020: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rThnwkbfec4",
        "colab_type": "code",
        "outputId": "8178ce36-fae4-46cd-cea9-935879d49766",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "from matplotlib import pyplot\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nY3yEBboxxvgIC3RjjPER/x+U8RtJH680kgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCCPg_3-UiTZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reverse_target_word_index=y_tokenizer.index_word\n",
        "reverse_source_word_index=x_tokenizer.index_word\n",
        "target_word_index=y_tokenizer.word_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyE-opZtsyuV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encode the input sequence to get the feature vector\n",
        "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
        "\n",
        "# Decoder setup\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_hidden_state_input = Input(shape=(max_text_len,latent_dim))\n",
        "\n",
        "# Get the embeddings of the decoder sequence\n",
        "dec_emb2= dec_emb_layer(decoder_inputs) \n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
        "\n",
        "#attention inference\n",
        "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
        "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
        "\n",
        "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "decoder_outputs2 = decoder_dense(decoder_inf_concat) \n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
        "    [decoder_outputs2] + [state_h2, state_c2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PD47VNBJTgh8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "    \n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "    \n",
        "    # Populate the first word of target sequence with the start word.\n",
        "    target_seq[0, 0] = target_word_index['sostok']\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "      \n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
        "        \n",
        "        if(sampled_token!='eostok'):\n",
        "            decoded_sentence += ' '+sampled_token\n",
        "\n",
        "        # Exit condition: either hit max length or find stop word.\n",
        "        if (sampled_token == 'eostok'  or len(decoded_sentence.split()) >= (max_summary_len-1)):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update internal states\n",
        "        e_h, e_c = h, c\n",
        "\n",
        "    return decoded_sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_o2mhcPT_xA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def seq2summary(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if(i!=0 and i!=target_word_index['sostok'] and i!=target_word_index['eostok']):\n",
        "            newString=newString+reverse_target_word_index[i]+' '\n",
        "    return newString\n",
        "\n",
        "def seq2text(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if(i!=0):\n",
        "            newString=newString+reverse_source_word_index[i]+' '\n",
        "    return newString"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSJATE_1UILq",
        "colab_type": "code",
        "outputId": "f68c5848-9691-4768-f05b-660db618577c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for i in range(0,25):\n",
        "    print(\"Review:\",seq2text(x_tr[i]))\n",
        "    print(\"Original summary:\",seq2summary(y_tr[i]))\n",
        "    print(\"Predicted summary:\",decode_sequence(x_tr[i].reshape(1,max_text_len)))\n",
        "    print(\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Review: and cooling effect the cooling effect of the erythritol is so powerful that is enhances the mint the chocolate the cotton candy aftertaste if you don't use too much erythritol \n",
            "Original summary: not a good flavor is much better \n",
            "Predicted summary:  good but not too sweet\n",
            "\n",
            "\n",
            "Review: cups that are available and this is in our top 3 we prefer a darker bolder flavor and this one hits the mark at the same time it's quite smooth \n",
            "Original summary: one of the best k cups \n",
            "Predicted summary:  good coffee\n",
            "\n",
            "\n",
            "Review: rich and it leaves no residue in the bottom of the kcup the other brand does maybe i got a bad batch overall i will happily buy this one again \n",
            "Original summary: excellent flavor \n",
            "Predicted summary:  wonderfully sweet\n",
            "\n",
            "\n",
            "Review: these individually wrapped pieces are delicious although i wish there were a few more mildly sweet with no sugar free aftertaste even a traditional marzipan should enjoy these \n",
            "Original summary: absolutely delicious \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: lowest phosphorus levels 0 73 which is quite beneficial for older cats' kidneys br i can heartily recommend it br especially at such fantastic and unbeatable anywhere price at amazon \n",
            "Original summary: that my 16 year old cat loves \n",
            "Predicted summary:  great for\n",
            "\n",
            "\n",
            "Review: this is it br br i'll admit i do salt the bacon just a tad before i fry it br br this is good stuff if you appreciate great bacon \n",
            "Original summary: the real deal almost \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: this makes for a great cup of coffee it's the brew strength for me and a nice flavor that has a little bite to it \n",
            "Original summary: my favorite \n",
            "Predicted summary:  great coffee\n",
            "\n",
            "\n",
            "Review: 90 of the seeds are up to an inch if i hadn't done this before the instructions would have been wonderful they left nothing out i will buy these again \n",
            "Original summary: cats love it too \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: sure how long the contamination will last i like the idea this product claims no gmo seeds yea you pay more but decided not to take a chance on japan \n",
            "Original summary: non \n",
            "Predicted summary: \n",
            "\n",
            "\n",
            "Review: varieties of hot chocolate k cups grove are by far the best they are very chocolaty rich creamy and leave very little sludge in the bottom of your cup yum \n",
            "Original summary: excellent hot chocolate \n",
            "Predicted summary:  best coffee ever\n",
            "\n",
            "\n",
            "Review: get more benefit from this coffee to me not the case i order my peet's arabian mocha java online for about 14 lb and it is still my favorite coffee \n",
            "Original summary: don't believe the \n",
            "Predicted summary:  great coffee\n",
            "\n",
            "\n",
            "Review: is the size of the can at 8 3 ounces it may be enough for a kid but you would need more than one of these to quench an thirst \n",
            "Original summary: the true soda \n",
            "Predicted summary:  good but not too sweet\n",
            "\n",
            "\n",
            "Review: coffees and have to admit disappointed in the selection several of ordinary coffees received also 2 of the flavors advertised which were my primary reason for ordering were not included \n",
            "Original summary: expected received \n",
            "Predicted summary:  good but not bad\n",
            "\n",
            "\n",
            "Review: the best coffee that i have tried and i tried many types of k cups wish it could be packaged in a larger package with more cups and sold cheaper \n",
            "Original summary: the best of what i tried \n",
            "Predicted summary:  great coffee\n",
            "\n",
            "\n",
            "Review: stingers are better tasting and more convenient than gels and work just as well to provide energy when exercising over long periods of time \n",
            "Original summary: best tasting energy boost \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: description i've noticed the packages from bed bath and beyond did not state this but can't imagine both are available i'll still purchase it because the flavor is so smooth \n",
            "Original summary: my favorite hazelnut k cup \n",
            "Predicted summary:  good tasting coffee\n",
            "\n",
            "\n",
            "Review: evolved yet immature taste buds is all i can say at this point start your babies off early and you won't have to habits of eating non food for fun \n",
            "Original summary: love and hate in same family \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: of these potatoes i have bought them at my local grocery store before and was disappointed that they were so small these are perfect tasty cook just right love 'em \n",
            "Original summary: tasty and perfect sized \n",
            "Predicted summary: \n",
            "\n",
            "\n",
            "Review: after br taste a href http www amazon com gp product wolfgang puck coffee rodeo drive blend medium roast 24 count k cups for keurig brewers pack of 2 a \n",
            "Original summary: wolfgang puck keurig cup coffee \n",
            "Predicted summary:  wolfgang puck coffee\n",
            "\n",
            "\n",
            "Review: description i've noticed the packages from bed bath and beyond did not state this but can't imagine both are available i'll still purchase it because the flavor is so smooth \n",
            "Original summary: my favorite hazelnut k cup \n",
            "Predicted summary:  good tasting coffee\n",
            "\n",
            "\n",
            "Review: very hard to find locally and online if you are dry curing meats this is necessary made excellent many times next i will have to try bacon the maple kind \n",
            "Original summary: makes great \n",
            "Predicted summary:  great\n",
            "\n",
            "\n",
            "Review: i see to these is that if you have an older microwave or one that is not as powerful at least 1100 the pork rinds do not cook as well \n",
            "Original summary: tasty \n",
            "Predicted summary: \n",
            "\n",
            "\n",
            "Review: time it is great on its own or as a creamy butter spread with cinnamon i certainly hope that amazon gets it stocked quickly my whole family loves this stuff \n",
            "Original summary: awesome \n",
            "Predicted summary:  best\n",
            "\n",
            "\n",
            "Review: flavors do come through the it seems to be a bit sweeter than orange juice have more satisfying and natural tasting fizzy juice drink by adding sparkling water to oj \n",
            "Original summary: sweet juice product \n",
            "Predicted summary:  good but not too sweet\n",
            "\n",
            "\n",
            "Review: each with 4 packs big mistake you only get four little pouches who would pay over 2 for a little squirt of applesauce don't make the same mistake buy elsewhere \n",
            "Original summary: huge \n",
            "Predicted summary: \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bn6EtduPUL7o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}